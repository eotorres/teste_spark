{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM//nfbV06np6WKlJgvXtnc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eotorres/teste_spark/blob/main/teste_spark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## criando o drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6m8PIcbM9PR",
        "outputId": "eda8d2e9-a4f5-4b8c-fc88-9a6c981d0ab8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criando a sessão e geraçao do dataframe"
      ],
      "metadata": {
        "id": "UmzPLMLwM-OW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Inicialize o SparkSession\n",
        "spark = SparkSession.builder.appName(\"TestApp\").getOrCreate()\n",
        "\n",
        "# Dados e colunas\n",
        "data = [\n",
        "    (\"Alice\", 34, \"Data Scientist\"),\n",
        "    (\"Bob\", 45, \"Data Engineer\"),\n",
        "    (\"Cathy\", 29, \"Data Analyst\"),\n",
        "    (\"David\", 35, \"Data Scientist\")\n",
        "]\n",
        "columns = [\"Name\", \"Age\", \"Occupation\"]\n",
        "\n",
        "# Crie o DataFrame\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "# Exiba o DataFrame\n",
        "df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcMEPnenM6r4",
        "outputId": "3dee8d13-e62c-44f9-fc37-c424cc26fe29"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+--------------+\n",
            "| Name|Age|    Occupation|\n",
            "+-----+---+--------------+\n",
            "|Alice| 34|Data Scientist|\n",
            "|  Bob| 45| Data Engineer|\n",
            "|Cathy| 29|  Data Analyst|\n",
            "|David| 35|Data Scientist|\n",
            "+-----+---+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fazendo a filtragem"
      ],
      "metadata": {
        "id": "r0MQZWPdNG5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecione as colunas \"Name\" e \"Age\"\n",
        "df_selected = df.select(\"Name\", \"Age\")\n",
        "\n",
        "# Filtre as linhas onde a \"Age\" é maior que 30\n",
        "df_filtered = df_selected.filter(df_selected[\"Age\"] > 30)\n",
        "\n",
        "# Exiba o resultado\n",
        "df_filtered.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RPpqhufNF4I",
        "outputId": "ba2e54a8-e37a-4deb-cab9-9bd6be0a397c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+\n",
            "| Name|Age|\n",
            "+-----+---+\n",
            "|Alice| 34|\n",
            "|  Bob| 45|\n",
            "|David| 35|\n",
            "+-----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Executando a Media"
      ],
      "metadata": {
        "id": "OJboz4wlNL2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import avg\n",
        "\n",
        "# Agrupe os dados pelo campo \"Occupation\" e calcule a média da \"Age\"\n",
        "df_grouped = df.groupBy(\"Occupation\").agg(avg(\"Age\").alias(\"AverageAge\"))\n",
        "\n",
        "# Exiba o resultado\n",
        "df_grouped.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_32NUrvNNLZ",
        "outputId": "9f4ed8a0-a3c5-468c-c200-f708ec412800"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+----------+\n",
            "|    Occupation|AverageAge|\n",
            "+--------------+----------+\n",
            "|Data Scientist|      34.5|\n",
            "| Data Engineer|      45.0|\n",
            "|  Data Analyst|      29.0|\n",
            "+--------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fazendo a ordenação"
      ],
      "metadata": {
        "id": "kodI76JLNQpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ordene o DataFrame pela média da \"Age\" em ordem decrescente\n",
        "df_sorted = df_grouped.orderBy(\"AverageAge\", ascending=False)\n",
        "\n",
        "# Exiba o resultado\n",
        "df_sorted.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJ2LZDmbNS5W",
        "outputId": "d66af9b2-7262-4e0a-a494-f6ca44568edd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+----------+\n",
            "|    Occupation|AverageAge|\n",
            "+--------------+----------+\n",
            "| Data Engineer|      45.0|\n",
            "|Data Scientist|      34.5|\n",
            "|  Data Analyst|      29.0|\n",
            "+--------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usando UDFs"
      ],
      "metadata": {
        "id": "zim0u48NNWce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "# Defina a função de categorização\n",
        "def age_category(age):\n",
        "    if age < 30:\n",
        "        return \"Jovem\"\n",
        "    elif 30 <= age <= 40:\n",
        "        return \"Adulto\"\n",
        "    else:\n",
        "        return \"Senior\"\n",
        "\n",
        "\n",
        "age_category_udf = udf(age_category, StringType())\n",
        "df_with_category = df.withColumn(\"AgeCategory\", age_category_udf(df[\"Age\"]))\n",
        "df_with_category.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRsHDmycNYi_",
        "outputId": "c1c8caa6-1062-4424-fa0c-7afbdc604db6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+--------------+-----------+\n",
            "| Name|Age|    Occupation|AgeCategory|\n",
            "+-----+---+--------------+-----------+\n",
            "|Alice| 34|Data Scientist|     Adulto|\n",
            "|  Bob| 45| Data Engineer|     Senior|\n",
            "|Cathy| 29|  Data Analyst|      Jovem|\n",
            "|David| 35|Data Scientist|     Adulto|\n",
            "+-----+---+--------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Diferença de idades entre pessoas"
      ],
      "metadata": {
        "id": "kCZvmCGNNhtl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import col, mean\n",
        "\n",
        "# Defina a janela para a média de idade por ocupação\n",
        "window_spec = Window.partitionBy(\"Occupation\")\n",
        "\n",
        "# Calcule a média de idade por ocupação e adicione a coluna de diferença\n",
        "df_with_age_diff = df.withColumn(\"AverageAgeByOccupation\", mean(\"Age\").over(window_spec)) \\\n",
        "                     .withColumn(\"AgeDifference\", col(\"Age\") - col(\"AverageAgeByOccupation\"))\n",
        "\n",
        "# Exiba o resultado\n",
        "df_with_age_diff.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54h-FxK-NmGe",
        "outputId": "3e5dcb47-da5a-4df4-d6d7-168d6530b058"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+--------------+----------------------+-------------+\n",
            "| Name|Age|    Occupation|AverageAgeByOccupation|AgeDifference|\n",
            "+-----+---+--------------+----------------------+-------------+\n",
            "|Cathy| 29|  Data Analyst|                  29.0|          0.0|\n",
            "|  Bob| 45| Data Engineer|                  45.0|          0.0|\n",
            "|Alice| 34|Data Scientist|                  34.5|         -0.5|\n",
            "|David| 35|Data Scientist|                  34.5|          0.5|\n",
            "+-----+---+--------------+----------------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Particionamento"
      ],
      "metadata": {
        "id": "xWlQ4tDxNq6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = '/content/drive/My Drive/particionado_por_occupation'\n",
        "df.write.partitionBy(\"Occupation\").format(\"parquet\").save(output_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "EwsaCXZTNsgg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Brodcast join"
      ],
      "metadata": {
        "id": "hFef9l9iNz3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import broadcast\n",
        "\n",
        "# Inicializa a sessão Spark\n",
        "spark = SparkSession.builder.appName(\"BroadcastJoinExample\").getOrCreate()\n",
        "\n",
        "# Cria dois DataFrames para o exemplo\n",
        "data1 = [(\"Alice\", \"Data Scientist\"),\n",
        "         (\"Bob\", \"Data Engineer\"),\n",
        "         (\"Cathy\", \"Data Analyst\")]\n",
        "\n",
        "data2 = [(\"Alice\", 34),\n",
        "         (\"Bob\", 45),\n",
        "         (\"Cathy\", 29)]\n",
        "\n",
        "columns1 = [\"Name\", \"Occupation\"]\n",
        "columns2 = [\"Name\", \"Age\"]\n",
        "\n",
        "df1 = spark.createDataFrame(data1, columns1)\n",
        "df2 = spark.createDataFrame(data2, columns2)\n",
        "\n",
        "# Realiza o join usando Broadcast\n",
        "df_joined = df1.join(broadcast(df2), \"Name\")\n",
        "df_joined.show()\n",
        "\n",
        "# Salvando o resultado do Broadcast Join no Google Drive como CSV\n",
        "df_joined.write.csv('/content/drive/My Drive/broadcast_join_result.csv', header=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHbdMllUN1cn",
        "outputId": "06ed73ed-24f5-490b-cbd7-9a4d230c0c85"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------+---+\n",
            "| Name|    Occupation|Age|\n",
            "+-----+--------------+---+\n",
            "|Alice|Data Scientist| 34|\n",
            "|  Bob| Data Engineer| 45|\n",
            "|Cathy|  Data Analyst| 29|\n",
            "+-----+--------------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Leitura de um arquivo CSV\n",
        "df = spark.read.csv('/content/drive/My Drive/broadcast_join_result.csv', header=True, inferSchema=True)\n",
        "# Escrever o DataFrame em formato Parquet\n",
        "df.write.parquet('/content/drive/My Drive/broadcast_join_result')\n"
      ],
      "metadata": {
        "id": "uCQCuQQmRTVj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## criando log\n",
        "import pandas as pd\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Função para gerar uma lista de timestamps\n",
        "def generate_timestamps(start_time, num_entries, interval_minutes=1):\n",
        "    return [(start_time + timedelta(minutes=i * interval_minutes)).strftime('%Y-%m-%d %H:%M:%S') for i in range(num_entries)]\n",
        "\n",
        "# Parâmetros para a geração de dados\n",
        "num_entries = 5000  # Número de entradas no log\n",
        "num_users = 100  # Número de usuários distintos\n",
        "actions = [\"login\", \"logout\", \"purchase\", \"view\", \"click\"]\n",
        "\n",
        "# Gerando os dados\n",
        "data = {\n",
        "    \"timestamp\": generate_timestamps(datetime(2024, 9, 1, 12, 0, 0), num_entries),\n",
        "    \"user_id\": [random.randint(1, num_users) for _ in range(num_entries)],\n",
        "    \"action\": [random.choice(actions) for _ in range(num_entries)]\n",
        "}\n",
        "\n",
        "# Criando o DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Salvando o DataFrame como CSV no Google Drive\n",
        "df.to_csv('/content/drive/My Drive/log_file_t.csv', index=False)\n",
        "\n",
        "print(\"Arquivo de log criado com sucesso.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOMgr5qzRYOJ",
        "outputId": "d22b8cb5-da54-4dc9-e7e0-e8e0f4a2e110"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo de log criado com sucesso.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Inicializando a sessão Spark\n",
        "spark = SparkSession.builder.appName(\"LogProcessing\").getOrCreate()\n",
        "\n",
        "# Montar o Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Caminho para o arquivo de log no Google Drive\n",
        "log_file_path = '/content/drive/My Drive/log_file_t.csv'\n",
        "\n",
        "# Leitura do arquivo de log\n",
        "df_log = spark.read.csv(log_file_path, header=True, inferSchema=True)\n",
        "\n",
        "# Contagem do número de ações por usuário\n",
        "df_actions_count = df_log.groupBy(\"user_id\").count()\n",
        "\n",
        "# Encontrando os 10 usuários mais ativos\n",
        "df_top_users = df_actions_count.orderBy(\"count\", ascending=False).limit(10)\n",
        "\n",
        "# Caminho para salvar o resultado no Google Drive\n",
        "output_path = '/content/drive/My Drive/top_users_t.csv'\n",
        "\n",
        "# Salvando o resultado em um arquivo CSV\n",
        "df_top_users.write.csv(output_path, header=True)\n",
        "\n",
        "print(\"Resultados salvos com sucesso.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pm8FNQoDR-JS",
        "outputId": "cf10c8e9-a256-43e3-d70f-1d87e23e16fe"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Resultados salvos com sucesso.\n"
          ]
        }
      ]
    }
  ]
}